import requests
import re
from collections import OrderedDict
import argparse
import time

# C·∫•u h√¨nh Telegram
TELEGRAM_BOT_TOKEN = '7318225955:AAF6ZD3Hxvtj_vDj6fgpW3E3HXfIyzN1LD4'  # Thay th·∫ø b·∫±ng token c·ªßa bot
TELEGRAM_CHAT_ID = '7371969470'      # Thay th·∫ø b·∫±ng chat ID c·ªßa b·∫°n

# C·∫•u h√¨nh regex v√† timeout
PROXY_PATTERN = re.compile(r'\b(?:[0-9]{1,3}\.){3}[0-9]{1,3}:[0-9]{1,5}\b')
REQUEST_TIMEOUT = 20

def send_file_to_telegram(file_path, caption):
    """G·ª≠i file v√† tin nh·∫Øn qua Telegram s·ª≠ d·ª•ng API"""
    url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendDocument"
    try:
        with open(file_path, 'rb') as file:
            files = {'document': file}
            data = {'chat_id': TELEGRAM_CHAT_ID, 'caption': caption}
            response = requests.post(url, files=files, data=data, timeout=60)
            if response.status_code != 200:
                print(f"üî¥ L·ªói khi g·ª≠i file: {response.text}")
            else:
                print("‚úÖ File v√† b√°o c√°o ƒë√£ ƒë∆∞·ª£c g·ª≠i th√†nh c√¥ng!")
    except Exception as e:
        print(f"üî¥ L·ªói khi g·ª≠i file: {str(e)}")

def fetch_proxies(url):
    """L·∫•y danh s√°ch proxy t·ª´ URL v·ªõi x·ª≠ l√Ω l·ªói n√¢ng cao"""
    try:
        response = requests.get(
            url, 
            timeout=REQUEST_TIMEOUT,
            headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36'}
        )
        
        if response.status_code != 200:
            return f"üî¥ HTTP {response.status_code}", [], response.status_code
            
        proxies = PROXY_PATTERN.findall(response.text)
        return ("‚úÖ Th√†nh c√¥ng", proxies, response.status_code) if proxies else ("üö´ Kh√¥ng c√≥ proxy", [], response.status_code)

    except requests.exceptions.Timeout:
        return "‚è≥ Timeout", [], None
    except requests.exceptions.RequestException as e:
        return f"üî¥ K·∫øt n·ªëi: {str(e)}", [], None
    except Exception as e:
        return f"üî¥ L·ªói: {str(e)}", [], None

def process_urls(file_path):
    """X·ª≠ l√Ω danh s√°ch URL v√† ph√¢n lo·∫°i k·∫øt qu·∫£"""
    with open(file_path, 'r') as f:
        urls = [line.strip() for line in f if line.strip()]

    results = {
        'success': [],
        'failed': [],
        'proxies': [],
        'total_time': 0.0
    }

    for url in urls:
        print(f"\nüîé ƒêang qu√©t: {url}")
        start = time.time()
        status, proxies, status_code = fetch_proxies(url)
        elapsed = time.time() - start

        if proxies:
            results['success'].append(url)
            results['proxies'].extend(proxies)
            print(f"üü¢ {status} | {len(proxies)} proxy | ‚è±Ô∏è {elapsed:.2f}s | M√£ tr·∫°ng th√°i: {status_code}")
        else:
            results['failed'].append((url, status, status_code))
            print(f"üî¥ {status} | ‚è±Ô∏è {elapsed:.2f}s | M√£ tr·∫°ng th√°i: {status_code}")

        print("‚îÅ" * 60)
    
    return results

def update_url_lists(results):
    """C·∫≠p nh·∫≠t file URL v√† ghi log l·ªói"""
    # Ghi l·∫°i URL th√†nh c√¥ng
    with open(args.list, 'w') as f:
        f.write('\n'.join(results['success']))
    
    # Ghi log l·ªói chi ti·∫øt k√®m m√£ tr·∫°ng th√°i
    if results['failed']:
        with open('urlerror.txt', 'w') as f:
            f.write("\n".join([f"{url} | {error} | M√£ tr·∫°ng th√°i: {status_code}" for url, error, status_code in results['failed']]))

def generate_report(results, exec_time):
    """T·∫°o b√°o c√°o ƒë·ªãnh d·∫°ng Markdown"""
    total_proxies = len(results['proxies'])
    unique_proxies = list(OrderedDict.fromkeys(results['proxies']))
    
    report = [
        "üì° **B√ÅO C√ÅO PROXY**",
        f"‚Ä¢ Proxy thu th·∫≠p: `{total_proxies}`",
        f"‚Ä¢ Proxy tr√πng l·∫∑p: `{total_proxies - len(unique_proxies)}`",
        f"‚Ä¢ Proxy h·ª£p l·ªá: `{len(unique_proxies)}`",
        f"‚Ä¢ URL th√†nh c√¥ng: `{len(results['success'])}`",
        f"‚Ä¢ URL th·∫•t b·∫°i: `{len(results['failed'])}`",
        f"\n‚è≥ Th·ªùi gian x·ª≠ l√Ω: `{exec_time:.2f}s`",
        f"üïí Chu k·ª≥ ti·∫øp theo sau: `5 ph√∫t`"
    ]
    
    if results['failed']:
        report.append("\nüî¥ **URL L·ªñI:**")
        report.extend([f"- `{url[:45]}...` | {error} | M√£ tr·∫°ng th√°i: {status_code}" for url, error, status_code in results['failed'][:5]])
    
    return '\n'.join(report)

def main():
    global args
    parser = argparse.ArgumentParser(description="C√¥ng c·ª• qu√©t proxy th√¥ng minh")
    parser.add_argument('-l', '--list', required=True, help="File ch·ª©a danh s√°ch URL")
    args = parser.parse_args()

    while True:
        start_time = time.time()
        
        # Th·ª±c hi·ªán qu√©t
        results = process_urls(args.list)
        unique_proxies = list(OrderedDict.fromkeys(results['proxies']))
        
        # L∆∞u k·∫øt qu·∫£
        with open('live.txt', 'w') as f:
            f.write('\n'.join(unique_proxies))
        
        # C·∫≠p nh·∫≠t danh s√°ch
        update_url_lists(results)
        
        # T·∫°o b√°o c√°o v√† g·ª≠i file qua Telegram
        exec_time = time.time() - start_time
        report = generate_report(results, exec_time)
        send_file_to_telegram('live.txt', report)
        
        print(f"\n‚è≥ T·ªïng th·ªùi gian: {exec_time:.2f}s")
        print(f"üïí B·∫Øt ƒë·∫ßu chu k·ª≥ m·ªõi sau 5 ph√∫t...\n{'‚ïê' * 50}")
        time.sleep(300)

if __name__ == "__main__":
    main()